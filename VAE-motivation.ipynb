{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import json\n",
    "import scipy.sparse as sparse\n",
    "import pickle\n",
    "import torch\n",
    "import misc.util as util\n",
    "from torch import nn\n",
    "\n",
    "import importlib\n",
    "from torch.utils.data import DataLoader\n",
    "from misc.loader import AEDataset\n",
    "from misc.util import *\n",
    "from tqdm.auto import tqdm\n",
    "from eval.rec_eval import *\n",
    "import neuralsort.pl as pl\n",
    "from models.loss import neuPrecLoss\n",
    "from misc.loader import RecDataset\n",
    "import models\n",
    "from models.loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/parsed/ml-1m-new\", 'rb') as f:\n",
    "    (tr_users, val_users, te_users, train_data, val_tr, val_te, te_tr, te_te) = pickle.load(f)\n",
    "empty = csr_matrix(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_items = train_data.shape\n",
    "ae_dataset = AEDataset(train_data[tr_users])\n",
    "total_anneal_steps = 50000\n",
    "anneal_cap = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vin = val_tr[val_users]\n",
    "vo = val_te[val_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['266.5675', '0.7016', '0.2832']\n",
      "['261.3681', '0.7340', '0.3041']\n",
      "['261.8279', '0.7524', '0.3088']\n",
      "['260.2758', '0.7639', '0.3088']\n",
      "['259.7892', '0.7671', '0.3070']\n",
      "['257.2447', '0.7792', '0.3141']\n",
      "['256.4285', '0.7788', '0.3117']\n",
      "['254.3275', '0.7789', '0.3121']\n",
      "['253.5939', '0.7799', '0.3052']\n",
      "['254.6119', '0.7742', '0.3104']\n",
      "['253.1598', '0.7708', '0.3081']\n",
      "['251.7246', '0.7705', '0.3056']\n",
      "['252.1712', '0.7684', '0.3072']\n",
      "['251.8128', '0.7716', '0.3064']\n",
      "['250.6313', '0.7693', '0.3077']\n",
      "['251.1596', '0.7724', '0.3031']\n",
      "['250.2956', '0.7709', '0.3061']\n",
      "['250.6282', '0.7716', '0.3058']\n",
      "['251.0723', '0.7739', '0.3047']\n",
      "['250.8794', '0.7736', '0.3058']\n"
     ]
    }
   ],
   "source": [
    "qed = []\n",
    "import models.ae\n",
    "importlib.reload(models.ae)\n",
    "import neuralsort.neuralobjs\n",
    "importlib.reload(models.ae)\n",
    "use_vae=True\n",
    "loader = DataLoader(ae_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "if use_vae:\n",
    "    model = models.ae.MultiVAE([200] + [n_items], dropout=0.5)\n",
    "else:\n",
    "    model = models.ae.MultiDAE([200] + [n_items], dropout=0.5)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5 * 1e-4)\n",
    "sc = neuralsort.neuralobjs.SC()\n",
    "lm = -1\n",
    "update_count = 0\n",
    "for epoch in (range(1, 500 + 1)):\n",
    "    model = model.train()\n",
    "    model.training = True\n",
    "    tr_losses = []\n",
    "    # train for one epoch\n",
    "    for uid, rowl in (loader):\n",
    "        row = rowl.float().cuda()\n",
    "        uid = uid.cuda() \n",
    "        loss = None \n",
    "        if use_vae:\n",
    "            scores, mu, logvar = model.forward(row)\n",
    "            if total_anneal_steps > 0:\n",
    "                anneal_cap = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            loss  = models.ae.loss_function(scores, row, mu, logvar)\n",
    "            update_count += 1\n",
    "        else:\n",
    "            scores = model.forward(row)\n",
    "            loss  = models.loss.MultinomialLoss(row, scores)\n",
    "            \n",
    "        (loss.mean()).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        tr_losses.append(loss.detach().unsqueeze(-1)) \n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch % 25 == 0):\n",
    "        tr_loss = torch.cat(tr_losses).mean()\n",
    "\n",
    "        model.eval()\n",
    "        model.training=False\n",
    "        wrapper1 = models.ae.implicitWrapper(model, train_data, naive_sparse2tensor, vae=True)\n",
    "        wrapper2 = models.ae.implicitWrapper(model, vin, naive_sparse2tensor, vae=True)\n",
    "        tr_ndcg = (ranking_metrics_at_k(wrapper1, empty, train_data, K=5, num_threads=4)['map'])\n",
    "        val_ndcg = (ranking_metrics_at_k(wrapper2, vin, vo, K=5, num_threads=4)['map'])\n",
    "\n",
    "        ret = (tr_loss.detach().cpu().numpy(), tr_ndcg, val_ndcg)\n",
    "        print([\"%0.4f\" % x for x in ret])\n",
    "        qed.append(ret)\n",
    "no_add = qed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['267.2704', '0.7743', '0.2899']\n",
      "['263.7904', '0.8155', '0.3108']\n",
      "['261.8874', '0.8376', '0.3187']\n",
      "['260.2988', '0.8458', '0.3285']\n",
      "['260.6927', '0.8588', '0.3278']\n",
      "['259.2096', '0.8630', '0.3303']\n",
      "['258.0349', '0.8649', '0.3254']\n",
      "['257.0943', '0.8645', '0.3260']\n",
      "['255.5931', '0.8669', '0.3258']\n",
      "['256.7205', '0.8649', '0.3245']\n",
      "['253.9212', '0.8626', '0.3222']\n",
      "['254.2529', '0.8613', '0.3194']\n",
      "['254.1992', '0.8585', '0.3198']\n",
      "['253.3537', '0.8567', '0.3197']\n",
      "['252.1020', '0.8520', '0.3163']\n",
      "['252.4483', '0.8529', '0.3133']\n",
      "['252.4604', '0.8517', '0.3202']\n",
      "['252.8360', '0.8519', '0.3164']\n",
      "['252.8104', '0.8545', '0.3167']\n",
      "['251.8477', '0.8549', '0.3145']\n"
     ]
    }
   ],
   "source": [
    "qed = []\n",
    "import models.ae\n",
    "importlib.reload(models.ae)\n",
    "import neuralsort.neuralobjs\n",
    "importlib.reload(models.ae)\n",
    "use_vae=True\n",
    "loader = DataLoader(ae_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "if use_vae:\n",
    "    model = models.ae.MultiVAE([200] + [n_items], dropout=0.5)\n",
    "else:\n",
    "    model = models.ae.MultiDAE([200] + [n_items], dropout=0.5)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5 * 1e-4)\n",
    "sc = neuralsort.neuralobjs.SC()\n",
    "lm = -1 \n",
    "\n",
    "update_count = 0\n",
    "for epoch in (range(1, 500 + 1)):\n",
    "    model = model.train()\n",
    "    model.training = True\n",
    "    tr_losses = []\n",
    "    # train for one epoch\n",
    "    for uid, rowl in (loader):\n",
    "        row = rowl.float().cuda()\n",
    "        uid = uid.cuda() \n",
    "        loss = None \n",
    "        if use_vae:\n",
    "            scores, mu, logvar = model.forward(row)\n",
    "            if total_anneal_steps > 0:\n",
    "                anneal_cap = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            loss  = models.ae.loss_function(scores, row, mu, logvar)\n",
    "            update_count += 1\n",
    "\n",
    "        else:\n",
    "            scores = model.forward(row)\n",
    "            loss  = models.loss.MultinomialLoss(row, scores)\n",
    "\n",
    "        loss2 = neuPrecLoss(sc, scores, row, topk=100, k=3, tau=15.0, use_top=True)\n",
    "        (loss.mean() + 30.0 * loss2.mean()).backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        tr_losses.append(loss.detach().unsqueeze(-1)) \n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch % 25 == 0):\n",
    "        #vind = torch.FloatTensor(np.asarray(vin.todense()).astype(np.float32)).cuda()\n",
    "        tr_loss = torch.cat(tr_losses).mean()\n",
    "\n",
    "        model.eval()\n",
    "        model.training=False\n",
    "        wrapper1 = models.ae.implicitWrapper(model, train_data, naive_sparse2tensor, vae=True)\n",
    "        wrapper2 = models.ae.implicitWrapper(model, vin, naive_sparse2tensor, vae=True)\n",
    "        tr_ndcg = (ranking_metrics_at_k(wrapper1, empty, train_data, K=5, num_threads=4)['map'])\n",
    "        val_ndcg = (ranking_metrics_at_k(wrapper2, vin, vo, K=5, num_threads=4)['map'])\n",
    "\n",
    "        ret = (tr_loss.detach().cpu().numpy(), tr_ndcg, val_ndcg)\n",
    "        print([\"%0.4f\" % x for x in ret])\n",
    "        qed.append(ret)\n",
    "add = qed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_add"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
