{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data', 'pinterest_iccv', 'board_to_info.pkl'),'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "with open(os.path.join('data', 'pinterest_iccv', 'pin_id_to_image_name.pkl'),'rb') as f:\n",
    "    b = pickle.load(f)\n",
    "    pid_to_imname = {x['pin_id']:x['im_name'] for x in b}\n",
    "uids = []\n",
    "iids = []\n",
    "rats = []\n",
    "for e, row in enumerate(data): \n",
    "    x = row['board_id']\n",
    "    y = row['pins']\n",
    "    uids.extend([e for _ in range(len(y))])\n",
    "    iids.extend([pid_to_imname[x] for x in y])\n",
    "    rats.extend([1 for _ in range(len(y))])\n",
    "raw_data = pd.DataFrame({\n",
    "    'userId' : uids,\n",
    "    'movieId': iids,\n",
    "    'rating': rats,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ita/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "min_uc=5\n",
    "min_sc=3\n",
    "dset = 'ml-1m'\n",
    "if dset == 'ml-20m':\n",
    "    raw_data = pd.read_csv(os.path.join('data', 'ml-20m', 'ratings.csv'), header=None)\n",
    "    raw_data = raw_data[raw_data['rating'] > 3.5]\n",
    "    n_heldout_users = 10000\n",
    "\n",
    "elif dset == \"ml-1m\":\n",
    "    raw_data = pd.read_csv(os.path.join('data', 'ml-1m', 'ratings.dat'), header=None, sep='::')\n",
    "    raw_data.columns =['userId', 'movieId', 'rating', 'ts']\n",
    "    raw_data = raw_data[raw_data['rating'] > 3.5]\n",
    "    n_heldout_users = 1000\n",
    "elif dset == 'melon':\n",
    "    raw_data = pd.read_json(os.path.join('data', 'melon', 'train.json'))\n",
    "    rows = []\n",
    "    cols = []\n",
    "    for i, r in raw_data.iterrows():\n",
    "        rows.extend([i] * len(r.songs))\n",
    "        cols.extend(r.songs)\n",
    "    raw_data = pd.DataFrame({\"userId\": rows, \"movieId\": cols})\n",
    "    min_sc = 30\n",
    "    n_heldout_users = 10000\n",
    "\n",
    "elif dset == 'anime':\n",
    "    raw_data = pd.read_csv(os.path.join(\"data\",\"anime\", \"rating.csv\"))\n",
    "    raw_data.columns = ['userId', 'movieId', 'rating']\n",
    "    n_heldout_users = 10000\n",
    "elif dset == 'epinion':\n",
    "    import scipy.io\n",
    "    rat = scipy.io.loadmat(\"data/epinion/rating_with_timestamp.mat\")['rating_with_timestamp']\n",
    "    u = rat[:, 0]\n",
    "    i = rat[:, 1]\n",
    "    r = rat[:, 3]\n",
    "    raw_data = pd.DataFrame({\n",
    "        'userId' : u,\n",
    "        'movieId': i,\n",
    "        'rating': r,\n",
    "    })\n",
    "elif dset == 'pinterest':\n",
    "    with open(os.path.join('data', 'pinterest_iccv', 'board_to_info.pkl'),'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    with open(os.path.join('data', 'pinterest_iccv', 'pin_id_to_image_name.pkl'),'rb') as f:\n",
    "        b = pickle.load(f)\n",
    "        pid_to_imname = {x['pin_id']:x['im_name'] for x in b}\n",
    "    uids = []\n",
    "    iids = []\n",
    "    rats = []\n",
    "    for e, row in enumerate(data): \n",
    "        x = row['board_id']\n",
    "        y = row['pins']\n",
    "        uids.extend([e for _ in range(len(y))])\n",
    "        iids.extend([pid_to_imname[x] for x in y])\n",
    "        rats.extend([1 for _ in range(len(y))])\n",
    "    raw_data = pd.DataFrame({\n",
    "        'userId' : uids,\n",
    "        'movieId': iids,\n",
    "        'rating': rats,\n",
    "    })\n",
    "    min_sc = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sc=10\n",
    "_raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=5, min_sc=min_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 572194 watching events from 6034 users and 2811 movies (sparsity: 3.373%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * _raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (_raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = _raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1867, 5662,  646, 3942, 1412, 5374, 4889, 1496, 2999, 3557,\n",
       "            ...\n",
       "            4483,  922, 1413, 2058, 4833, 5046, 4015, 1389, 3572, 3863],\n",
       "           dtype='int64', name='userId', length=6034)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plays = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['uid'] = raw_data.userId.apply(lambda x : profile2id[x] if x in profile2id else -1)\n",
    "raw_data['iid']  = raw_data.movieId.apply(lambda x: show2id[x] if x in show2id else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = raw_data.groupby('uid').iid.apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import *\n",
    "\n",
    "def leavek(data, k=1, tots=100):\n",
    "    n_items = len(show2id)\n",
    "    _pos, _neg = [], []\n",
    "    for i, t in enumerate(data.itertuples()):\n",
    "        uid = t.uid\n",
    "        iids = t.iid\n",
    "        negs = np.random.choice(iids, k).tolist()\n",
    "        while len(negs) < tots:\n",
    "            negs += [x for x in np.random.choice(n_items, tots * 2).tolist() if x not in iids]\n",
    "        negs = negs[:tots]\n",
    "        poss = [x for x in iids if x not in negs]\n",
    "        _pos.append(poss)\n",
    "        _neg.append(negs)\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print(i+1, \"user sampled!\")\n",
    "    return _pos, _neg\n",
    "\n",
    "def lltomat(pos):\n",
    "    x = lil_matrix((len(profile2id), len(show2id)))\n",
    "    for u, i in enumerate(pos):\n",
    "        x[u, i] = 1\n",
    "    return x.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 user sampled!\n",
      "2000 user sampled!\n",
      "3000 user sampled!\n",
      "4000 user sampled!\n",
      "5000 user sampled!\n",
      "6000 user sampled!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "for tots in [100]:#, 300, 500]:\n",
    "    for k in [1]:#, 3, 5]:\n",
    "        pos, neg = leavek(ret, k=k, tots=tots)\n",
    "        pos_mat = lltomat(pos)\n",
    "        p = os.path.join('data','parsed', '%s-l-%d-%d' %(dset, k, tots))\n",
    "        with open(p, 'wb') as f:\n",
    "            pickle.dump((pos_mat, np.array(neg, dtype=np.int32)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ita/Dropbox/code/neurank/code'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
