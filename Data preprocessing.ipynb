{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ita/code/drm\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the dataset\n",
    "#### Please input the dataset name in this list: `['ml-20m', 'sketchfab', 'epinion', 'melon']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "mkdir: data/parsed: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!mkdir data/parsed\n",
    "dset = 'sketchfab'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to set locale category LC_NUMERIC to en_KR.\n",
      "Warning: Failed to set locale category LC_TIME to en_KR.\n",
      "Warning: Failed to set locale category LC_COLLATE to en_KR.\n",
      "Warning: Failed to set locale category LC_MONETARY to en_KR.\n",
      "Warning: Failed to set locale category LC_MESSAGES to en_KR.\n",
      "--2020-09-15 01:46:45--  https://raw.githubusercontent.com/EthanRosenthal/rec-a-sketch/master/data/model_likes_anon.psv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.192.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 54494858 (52M) [text/plain]\n",
      "Saving to: ‘data/sketchfab/model_likes_anon.psv’\n",
      "\n",
      "data/sketchfab/mode 100%[===================>]  51.97M  6.97MB/s    in 7.5s    \n",
      "\n",
      "2020-09-15 01:46:54 (6.92 MB/s) - ‘data/sketchfab/model_likes_anon.psv’ saved [54494858/54494858]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_uc=5\n",
    "min_sc=3\n",
    "\n",
    "if dset == 'ml-20m':\n",
    "    !wget -c -O data/ml-20m.zip http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
    "    if not os.path.isdir('./data/ml-20m'):\n",
    "        !unzip -d data/ data/ml-20m.zip\n",
    "    raw_data = pd.read_csv(os.path.join('data', 'ml-20m', 'ratings.csv'))\n",
    "    raw_data.columns = ['userId', 'movieId', 'rating', 'ts']\n",
    "    raw_data = raw_data[raw_data['rating'] > 3.5]\n",
    "\n",
    "elif dset == 'sketchfab':\n",
    "    !mkdir data/sketchfab\n",
    "    !wget -c -O data/sketchfab/model_likes_anon.psv https://raw.githubusercontent.com/EthanRosenthal/rec-a-sketch/master/data/model_likes_anon.psv\n",
    "    raw_data = pd.read_csv(os.path.join('data', 'sketchfab', 'model_likes_anon.psv'), \n",
    "                           delimiter='|', \n",
    "                           quotechar='\\\\')\n",
    "    raw_data['userId'] = raw_data['uid'].astype(\"object\")\n",
    "    raw_data['movieId'] = raw_data['mid'].astype(\"object\")\n",
    "    min_sc = 5\n",
    "    \n",
    "elif dset == 'melon':\n",
    "    raw_data = pd.read_json(os.path.join('data', 'melon', 'train.json'))\n",
    "    print(raw_data)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    for i, r in raw_data.iterrows():\n",
    "        rows.extend([i] * len(r.songs))\n",
    "        cols.extend(r.songs)\n",
    "    raw_data = pd.DataFrame({\"userId\": rows, \"movieId\": cols})\n",
    "    min_sc = 10\n",
    "\n",
    "elif dset == 'epinion':\n",
    "    !wget -c -O data/epinion.zip https://www.cse.msu.edu/~tangjili/datasetcode/epinions_with_rating_timestamp.zip\n",
    "    if not os.path.isdir('./data/epinion_with_rating_timestamp'):\n",
    "        !unzip -d data/ data/epinion.zip\n",
    "    import scipy.io\n",
    "    rat = scipy.io.loadmat(\"data/epinion_with_rating_timestamp/rating_with_timestamp.mat\")['rating_with_timestamp']\n",
    "    u = rat[:, 0]\n",
    "    i = rat[:, 1]\n",
    "    r = rat[:, 3]\n",
    "    raw_data = pd.DataFrame({\n",
    "        'userId' : u,\n",
    "        'movieId': i,\n",
    "        'rating': r,\n",
    "    })\n",
    "    print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=min_uc, min_sc=min_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 559081 watching events from 15560 users and 28703 movies (sparsity: 99.875%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. - _raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (_raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = _raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = raw_data\n",
    "unique_sid = pd.unique(plays['movieId'])\n",
    "unique_uid = pd.unique(plays['userId'])\n",
    "n_users = len(unique_uid)\n",
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    row, col = tp.userId.apply(lambda x: profile2id[x]).tolist(), tp.movieId.apply(lambda x: show2id[x]).tolist()\n",
    "    return sparse.coo_matrix((np.ones_like(row), (row, col)), shape=(len(profile2id), len(show2id))).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numerize(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 15557, 15558, 15559]), 15560)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.arange(n_users)\n",
    "r[np.asarray(data.sum(1)).ravel() > 0], len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.evaluation import train_test_split\n",
    "total = data\n",
    "train, te = train_test_split(total, 0.8)\n",
    "tr, val = train_test_split(train, 0.875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(f'./data/parsed'):\n",
    "    !mkdir ./data/parsed\n",
    "with open(f'data/parsed/{dset}-parsed', 'wb') as f:\n",
    "    pickle.dump((tr, val, te), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<15560x28703 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 391260 stored elements in Compressed Sparse Row format>, <15560x28703 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 55814 stored elements in Compressed Sparse Row format>, <15560x28703 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 111864 stored elements in Compressed Sparse Row format>)\n"
     ]
    }
   ],
   "source": [
    "with open(f'data/parsed/{dset}-parsed', 'rb') as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
