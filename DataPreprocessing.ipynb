{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ita/drm_test\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the dataset\n",
    "#### Please input the dataset name in this list: `['ml-20m', 'sketchfab', 'epinion', 'melon']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘drm_data’: File exists\n",
      "mkdir: cannot create directory ‘drm_data/parsed’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir drm_data\n",
    "!mkdir drm_data/parsed\n",
    "dset = 'epinion'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-15 01:21:50--  https://www.cse.msu.edu/~tangjili/datasetcode/epinions_with_rating_timestamp.zip\n",
      "Resolving www.cse.msu.edu (www.cse.msu.edu)... 35.9.20.103\n",
      "Connecting to www.cse.msu.edu (www.cse.msu.edu)|35.9.20.103|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6289772 (6.0M) [application/zip]\n",
      "Saving to: ‘drm_data/epinion.zip’\n",
      "\n",
      "drm_data/epinion.zi 100%[===================>]   6.00M  68.8KB/s    in 2m 15s  \n",
      "\n",
      "2020-09-15 01:24:07 (45.6 KB/s) - ‘drm_data/epinion.zip’ saved [6289772/6289772]\n",
      "\n",
      "Archive:  drm_data/epinion.zip\n",
      "   creating: drm_data/epinion_with_rating_timestamp/\n",
      "  inflating: drm_data/epinion_with_rating_timestamp/rating_with_timestamp.mat  \n",
      "  inflating: drm_data/epinion_with_rating_timestamp/trust.mat  \n",
      "        userId  movieId  rating\n",
      "0            1        1       2\n",
      "1            1        2       2\n",
      "2            1        3       2\n",
      "3            1        4       5\n",
      "4            1        5       3\n",
      "...        ...      ...     ...\n",
      "922262   22166    83922       4\n",
      "922263   22166    23442       4\n",
      "922264   22166    43538       5\n",
      "922265   22166    38711       4\n",
      "922266   22166    41790       3\n",
      "\n",
      "[922267 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "min_uc=5\n",
    "min_sc=3\n",
    "\n",
    "if dset == 'ml-20m':\n",
    "    !wget -c -O drm_data/ml-20m.zip http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
    "    if not os.path.isdir('./drm_data/ml-20m'):\n",
    "        !unzip -d drm_data/ drm_data/ml-20m.zip\n",
    "    raw_data = pd.read_csv(os.path.join('drm_data', 'ml-20m', 'ratings.csv'))\n",
    "    raw_data.columns = ['userId', 'movieId', 'rating', 'ts']\n",
    "    raw_data = raw_data[raw_data['rating'] > 3.5]\n",
    "\n",
    "elif dset == 'sketchfab':\n",
    "    !mkdir drm_data/sketchfab\n",
    "    !wget -c -O drm_data/sketchfab/model_likes_anon.psv https://raw.githubusercontent.com/EthanRosenthal/rec-a-sketch/master/data/model_likes_anon.psv\n",
    "    raw_data = pd.read_csv(os.path.join('drm_data', 'sketchfab', 'model_likes_anon.psv'), \n",
    "                           delimiter='|', \n",
    "                           quotechar='\\\\')\n",
    "    raw_data['userId'] = raw_data['uid'].astype(\"object\")\n",
    "    raw_data['movieId'] = raw_data['mid'].astype(\"object\")\n",
    "    min_sc = 5\n",
    "    \n",
    "elif dset == 'melon':\n",
    "    raw_data = pd.read_json(os.path.join('drm_data', 'melon', 'train.json'))\n",
    "    print(raw_data)\n",
    "    rows = []\n",
    "    cols = []\n",
    "    for i, r in raw_data.iterrows():\n",
    "        rows.extend([i] * len(r.songs))\n",
    "        cols.extend(r.songs)\n",
    "    raw_data = pd.DataFrame({\"userId\": rows, \"movieId\": cols})\n",
    "    min_sc = 10\n",
    "\n",
    "elif dset == 'epinion':\n",
    "    !wget -c -O drm_data/epinion.zip https://www.cse.msu.edu/~tangjili/datasetcode/epinions_with_rating_timestamp.zip\n",
    "    if not os.path.isdir('./drm_data/epinion_with_rating_timestamp'):\n",
    "        !unzip -d drm_data/ drm_data/epinion.zip\n",
    "    import scipy.io\n",
    "    rat = scipy.io.loadmat(\"drm_data/epinion_with_rating_timestamp/rating_with_timestamp.mat\")['rating_with_timestamp']\n",
    "    u = rat[:, 0]\n",
    "    i = rat[:, 1]\n",
    "    r = rat[:, 3]\n",
    "    raw_data = pd.DataFrame({\n",
    "        'userId' : u,\n",
    "        'movieId': i,\n",
    "        'rating': r,\n",
    "    })\n",
    "    print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep items that are clicked on by at least 5 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "_raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=min_uc, min_sc=min_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 640918 watching events from 21396 users and 59377 movies (sparsity: 99.950%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. - _raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (_raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = _raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = raw_data\n",
    "unique_sid = pd.unique(plays['movieId'])\n",
    "unique_uid = pd.unique(plays['userId'])\n",
    "n_users = len(unique_uid)\n",
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    row, col = tp.userId.apply(lambda x: profile2id[x]).tolist(), tp.movieId.apply(lambda x: show2id[x]).tolist()\n",
    "    return sparse.coo_matrix((np.ones_like(row), (row, col)), shape=(len(profile2id), len(show2id))).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = numerize(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 21393, 21394, 21395]), 21396)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.arange(n_users)\n",
    "r[np.asarray(data.sum(1)).ravel() > 0], len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.evaluation import train_test_split\n",
    "total = data\n",
    "train, te = train_test_split(total, 0.8)\n",
    "tr, val = train_test_split(train, 0.875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(f'./data/parsed'):\n",
    "    !mkdir ./data/parsed\n",
    "with open(f'data/parsed/{dset}-parsed', 'wb') as f:\n",
    "    pickle.dump((tr, val, te), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<21396x59377 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 442122 stored elements in Compressed Sparse Row format>, <21396x59377 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 62852 stored elements in Compressed Sparse Row format>, <21396x59377 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 126448 stored elements in Compressed Sparse Row format>)\n"
     ]
    }
   ],
   "source": [
    "with open(f'data/parsed/{dset}-parsed', 'rb') as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
